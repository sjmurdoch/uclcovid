{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pdn\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FIELDS = {\n",
    "    9: \"staff.on\",\n",
    "    10: \"staff.off\",\n",
    "    11: \"student.on\",\n",
    "    12: \"student.off\",\n",
    "    \n",
    "    14: \"staff7.on\",\n",
    "    15: \"staff7.off\",\n",
    "    16: \"student7.on\",\n",
    "    17: \"student7.off\",\n",
    "    \n",
    "    19: \"stafftotal.on\",\n",
    "    20: \"stafftotal.off\",\n",
    "    21: \"studenttotal.on\",\n",
    "    22: \"studenttotal.off\",\n",
    "}\n",
    "TEXT_FIELDS = {\n",
    "    1: \"Staff\",\n",
    "    2: \"Students\",\n",
    "    4: \"On campus *\",\n",
    "    5: \"Off campus **\",\n",
    "    6: \"On campus *\",\n",
    "    7: \"Off campus **\",\n",
    "    8: \"New cases in last counted 24 hour period ***\",\n",
    "    13: \"New cases in last counted 7 day period ***\",\n",
    "    18: \"Total cases since 28 Sept 2020 (start of Term 1)\",\n",
    "}\n",
    "\n",
    "DEBUG=False\n",
    "MONDAY = 0\n",
    "DATE_LABEL = 'date'\n",
    "DATASET_NAMES = ['staff.on', 'staff.off', 'student.on', 'student.off',\n",
    "                 'staff7.on', 'staff7.off', 'student7.on', 'student7.off',\n",
    "                 'stafftotal.on', 'stafftotal.off', 'studenttotal.on', 'studenttotal.off']\n",
    "\n",
    "## These figures need smoothing over the weekend\n",
    "SMOOTHED_NAMES = ['staff.on', 'staff.off', 'student.on', 'student.off']\n",
    "\n",
    "def debug_log(*args):\n",
    "    if DEBUG:\n",
    "        print(*args, file=sys.stderr)\n",
    "\n",
    "def parse_file(fh):\n",
    "    soup = BeautifulSoup(fh, 'html.parser')\n",
    "    table = soup.select_one('#current-confirmed-cases-covid-19 > div.site-content.wrapper > div > div > div > article > div > table')\n",
    "    data = {}\n",
    "    for i, tag in enumerate(table.find_all([\"td\",\"th\"])):\n",
    "        if i in text_fields:\n",
    "            assert(tag.string == TEXT_FIELDS[i])\n",
    "        elif i in DATA_FIELDS:\n",
    "            data[DATA_FIELDS[i]] = int(tag.string)\n",
    "            \n",
    "    return table, data\n",
    "        \n",
    "def to_json(df, jsonfile):\n",
    "    datasets = defaultdict(list)\n",
    "    for n, rows in df.iteritems():\n",
    "        ds = datasets[n]\n",
    "        for d, v in rows.iteritems():\n",
    "            ds.append((d.strftime(\"%Y-%m-%d\"), v))\n",
    "    json.dump(datasets, jsonfile, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_fields' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1b2c6bbaa9a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m## other days, data is correct as of previous day at 5pm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mdata_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_date\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlast_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-bd920b83b61b>\u001b[0m in \u001b[0;36mparse_file\u001b[1;34m(fh)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"td\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"th\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTEXT_FIELDS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDATA_FIELDS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_fields' is not defined"
     ]
    }
   ],
   "source": [
    "p = Path('../data')\n",
    "duplicates = p / 'duplicates'\n",
    "duplicates.mkdir(exist_ok=True)\n",
    "last_data = None\n",
    "\n",
    "## Data to build into PANDAS dataframe\n",
    "pd_data = []\n",
    "\n",
    "for file in p.glob(\"covid-*.html\"):\n",
    "    debug_log(\"Loading from\", file)\n",
    "    \n",
    "    with file.open() as fh:\n",
    "        file_date = datetime.strptime(file.name, \"covid-%Y-%m-%dT%H-%M-%S.html\").date()\n",
    "        if file_date.weekday() == 0:\n",
    "            ## Monday, data is correct as of Friday 5pm\n",
    "            data_date = file_date - timedelta(days = 3)\n",
    "        else:\n",
    "            ## other days, data is correct as of previous day at 5pm\n",
    "            data_date = file_date - timedelta(days = 1)\n",
    "        table, data = parse_file(fh)\n",
    "    \n",
    "    if data != last_data:\n",
    "        debug_log(\"New data at\", file_date)\n",
    " \n",
    "        pd_row = []\n",
    "        pd_row.append(data_date)\n",
    "        for n in DATASET_NAMES:\n",
    "            pd_row.append(data[n])\n",
    "        pd_data.append(pd_row)\n",
    "        \n",
    "        last_data = data\n",
    "    else:\n",
    "        debug_log(\"File is a duplicate\", file.name)\n",
    "        #file.rename(duplicates / file.name)\n",
    "\n",
    "## Create the PANDAS data frame\n",
    "df = pd.DataFrame(pd_data, columns = [DATE_LABEL] + DATASET_NAMES, dtype='float64')\n",
    "df.set_index(DATE_LABEL, inplace=True, verify_integrity=True)\n",
    "\n",
    "## Export raw data to CSV\n",
    "with open(\"../data/covid_raw.csv\", \"w\") as csvfile:\n",
    "    df.to_csv(csvfile, line_terminator=\"\\r\\n\")\n",
    "\n",
    "## Export raw data to JSON\n",
    "with open(\"../data/covid_raw.json\", \"w\") as jsonfile:\n",
    "    to_json(df, jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add weekend data\n",
    "extra_rows = []\n",
    "for d in df.index:\n",
    "    if d.weekday() == MONDAY:\n",
    "        ## Share weekend + Monday data over three days\n",
    "        extra = df.loc[d, SMOOTHED_NAMES] / 3.0\n",
    "        ## Replace Monday data with its share\n",
    "        df.loc[d, SMOOTHED_NAMES] = extra\n",
    "        ## Add in Saturday and Sunday's data\n",
    "        for i in [2, 1]:\n",
    "            entry_date = d - timedelta(days = i)\n",
    "            extra_rows.append([entry_date] + list(extra))\n",
    "\n",
    "extra_df = pd.DataFrame(extra_rows, columns=[DATE_LABEL] + SMOOTHED_NAMES, dtype='float64')\n",
    "extra_df.set_index(DATE_LABEL, inplace=True, verify_integrity=True)\n",
    "df_smoothed = pd.concat([df, extra_df])\n",
    "df_smoothed.sort_index(inplace=True)\n",
    "\n",
    "## Export smoothed data to CSV\n",
    "with open(\"../data/covid.csv\", \"w\") as csvfile:\n",
    "    df_smoothed.to_csv(csvfile, line_terminator=\"\\r\\n\")\n",
    "\n",
    "## Export smoothed data to JSON\n",
    "with open(\"../data/covid.json\", \"w\") as jsonfile:\n",
    "    to_json(df_smoothed, jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(table.find_all([\"td\",\"th\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
