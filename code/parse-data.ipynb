{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fields = {\n",
    "    9: \"staff.on\",\n",
    "    10: \"staff.off\",\n",
    "    11: \"student.on\",\n",
    "    12: \"student.off\",\n",
    "    \n",
    "    14: \"staff7.on\",\n",
    "    15: \"staff7.off\",\n",
    "    16: \"student7.on\",\n",
    "    17: \"student7.off\",\n",
    "    \n",
    "    19: \"stafftotal.on\",\n",
    "    20: \"stafftotal.off\",\n",
    "    21: \"studenttotal.on\",\n",
    "    22: \"studenttotal.off\",\n",
    "}\n",
    "text_fields = {\n",
    "    1: \"Staff\",\n",
    "    2: \"Students\",\n",
    "    4: \"On campus *\",\n",
    "    5: \"Off campus **\",\n",
    "    6: \"On campus *\",\n",
    "    7: \"Off campus **\",\n",
    "    8: \"New cases in last counted 24 hour period ***\",\n",
    "    13: \"New cases in last counted 7 day period ***\",\n",
    "    18: \"Total cases since 28 Sept 2020 (start of Term 1)\",\n",
    "}\n",
    "\n",
    "TUESDAY = 1\n",
    "\n",
    "def parse_file(fh):\n",
    "    soup = BeautifulSoup(fh, 'html.parser')\n",
    "    table = soup.select_one('#current-confirmed-cases-covid-19 > div.site-content.wrapper > div > div > div > article > div > table')\n",
    "    data = {}\n",
    "    for i, tag in enumerate(table.find_all([\"td\",\"th\"])):\n",
    "        if i in text_fields:\n",
    "            assert(tag.string == text_fields[i])\n",
    "        elif i in data_fields:\n",
    "            data[data_fields[i]] = int(tag.string)\n",
    "            \n",
    "    return table, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ..\\data\\covid-2020-10-12T20-01-30.html\n",
      "New data at 2020-10-12\n",
      "Loading from ..\\data\\covid-2020-10-12T20-42-01.html\n",
      "File is a duplicate covid-2020-10-12T20-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-12T21-42-01.html\n",
      "File is a duplicate covid-2020-10-12T21-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-12T22-42-01.html\n",
      "File is a duplicate covid-2020-10-12T22-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-12T23-42-01.html\n",
      "File is a duplicate covid-2020-10-12T23-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T00-42-02.html\n",
      "File is a duplicate covid-2020-10-13T00-42-02.html\n",
      "Loading from ..\\data\\covid-2020-10-13T01-42-02.html\n",
      "File is a duplicate covid-2020-10-13T01-42-02.html\n",
      "Loading from ..\\data\\covid-2020-10-13T02-42-01.html\n",
      "File is a duplicate covid-2020-10-13T02-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T03-42-01.html\n",
      "File is a duplicate covid-2020-10-13T03-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T04-42-01.html\n",
      "File is a duplicate covid-2020-10-13T04-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T05-42-01.html\n",
      "File is a duplicate covid-2020-10-13T05-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T06-42-01.html\n",
      "File is a duplicate covid-2020-10-13T06-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T07-42-01.html\n",
      "File is a duplicate covid-2020-10-13T07-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T08-42-01.html\n",
      "File is a duplicate covid-2020-10-13T08-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T09-42-01.html\n",
      "File is a duplicate covid-2020-10-13T09-42-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T09-46-51.html\n",
      "File is a duplicate covid-2020-10-13T09-46-51.html\n",
      "Loading from ..\\data\\covid-2020-10-13T09-51-01.html\n",
      "File is a duplicate covid-2020-10-13T09-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T10-51-01.html\n",
      "File is a duplicate covid-2020-10-13T10-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T11-51-01.html\n",
      "File is a duplicate covid-2020-10-13T11-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T12-51-01.html\n",
      "File is a duplicate covid-2020-10-13T12-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T13-51-01.html\n",
      "File is a duplicate covid-2020-10-13T13-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T14-51-01.html\n",
      "File is a duplicate covid-2020-10-13T14-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T15-51-01.html\n",
      "File is a duplicate covid-2020-10-13T15-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T16-51-01.html\n",
      "File is a duplicate covid-2020-10-13T16-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T17-51-01.html\n",
      "File is a duplicate covid-2020-10-13T17-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T18-51-01.html\n",
      "File is a duplicate covid-2020-10-13T18-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T19-51-01.html\n",
      "File is a duplicate covid-2020-10-13T19-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T20-51-01.html\n",
      "File is a duplicate covid-2020-10-13T20-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T21-51-01.html\n",
      "New data at 2020-10-13\n",
      "Loading from ..\\data\\covid-2020-10-13T22-51-01.html\n",
      "File is a duplicate covid-2020-10-13T22-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-13T23-51-01.html\n",
      "File is a duplicate covid-2020-10-13T23-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T00-51-01.html\n",
      "File is a duplicate covid-2020-10-14T00-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T01-51-01.html\n",
      "File is a duplicate covid-2020-10-14T01-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T02-51-01.html\n",
      "File is a duplicate covid-2020-10-14T02-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T03-51-01.html\n",
      "File is a duplicate covid-2020-10-14T03-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T04-51-01.html\n",
      "File is a duplicate covid-2020-10-14T04-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T05-51-01.html\n",
      "File is a duplicate covid-2020-10-14T05-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T06-51-01.html\n",
      "File is a duplicate covid-2020-10-14T06-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T07-51-01.html\n",
      "File is a duplicate covid-2020-10-14T07-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T08-51-01.html\n",
      "New data at 2020-10-14\n",
      "Loading from ..\\data\\covid-2020-10-14T09-51-01.html\n",
      "File is a duplicate covid-2020-10-14T09-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T10-51-01.html\n",
      "File is a duplicate covid-2020-10-14T10-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T11-51-01.html\n",
      "File is a duplicate covid-2020-10-14T11-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T12-51-01.html\n",
      "File is a duplicate covid-2020-10-14T12-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T13-51-01.html\n",
      "File is a duplicate covid-2020-10-14T13-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T14-51-01.html\n",
      "File is a duplicate covid-2020-10-14T14-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T15-51-01.html\n",
      "File is a duplicate covid-2020-10-14T15-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T16-51-01.html\n",
      "File is a duplicate covid-2020-10-14T16-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T17-51-01.html\n",
      "File is a duplicate covid-2020-10-14T17-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T18-51-01.html\n",
      "File is a duplicate covid-2020-10-14T18-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T19-51-01.html\n",
      "File is a duplicate covid-2020-10-14T19-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T20-51-01.html\n",
      "File is a duplicate covid-2020-10-14T20-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T21-51-01.html\n",
      "File is a duplicate covid-2020-10-14T21-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T22-51-01.html\n",
      "File is a duplicate covid-2020-10-14T22-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-14T23-51-01.html\n",
      "File is a duplicate covid-2020-10-14T23-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T00-51-01.html\n",
      "File is a duplicate covid-2020-10-15T00-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T01-51-01.html\n",
      "File is a duplicate covid-2020-10-15T01-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T02-51-01.html\n",
      "File is a duplicate covid-2020-10-15T02-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T03-51-01.html\n",
      "File is a duplicate covid-2020-10-15T03-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T04-51-02.html\n",
      "File is a duplicate covid-2020-10-15T04-51-02.html\n",
      "Loading from ..\\data\\covid-2020-10-15T05-51-01.html\n",
      "File is a duplicate covid-2020-10-15T05-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T06-51-01.html\n",
      "File is a duplicate covid-2020-10-15T06-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T07-51-01.html\n",
      "File is a duplicate covid-2020-10-15T07-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T08-51-01.html\n",
      "File is a duplicate covid-2020-10-15T08-51-01.html\n",
      "Loading from ..\\data\\covid-2020-10-15T09-51-01.html\n",
      "New data at 2020-10-15\n"
     ]
    }
   ],
   "source": [
    "p = Path('../data')\n",
    "duplicates = p / 'duplicates'\n",
    "duplicates.mkdir(exist_ok=True)\n",
    "last_data = None\n",
    "dataset_names = ['staff.on', 'staff.off', 'student.on', 'student.off',\n",
    "                 'staff7.on', 'staff7.off', 'student7.on', 'student7.off',\n",
    "                 'stafftotal.on', 'stafftotal.off', 'studenttotal.on', 'studenttotal.off']\n",
    "\n",
    "## These figures need smoothing over the weekend\n",
    "smoothed_names = set(['staff.on', 'staff.off', 'student.on', 'student.off'])\n",
    "\n",
    "datasets = {} # For JSON\n",
    "rows = [] # For CSV\n",
    "\n",
    "## CSV header\n",
    "rows.append([\"date\"] + dataset_names)\n",
    "\n",
    "for file in p.glob(\"covid-*.html\"):\n",
    "    print(\"Loading from\", file)\n",
    "    fh = file.open()\n",
    "    file_date = datetime.strptime(file.name, \"covid-%Y-%m-%dT%H-%M-%S.html\").date()\n",
    "    if file_date.weekday() == 0:\n",
    "        ## Monday, data is correct as of Friday 5pm\n",
    "        data_date = file_date - timedelta(days = 3)\n",
    "    else:\n",
    "        ## other days, data is correct as of previous day at 5pm\n",
    "        data_date = file_date - timedelta(days = 1)\n",
    "    table, data = parse_file(fh)\n",
    "    fh.close()\n",
    "    \n",
    "    if data != last_data:\n",
    "        print(\"New data at\", file_date)\n",
    "        \n",
    "        ## JSON data\n",
    "        for n in dataset_names:\n",
    "            v = data[n]\n",
    "            ds = datasets.setdefault(n, [])\n",
    "            if file_date.weekday() == TUESDAY and n in smoothed_names:\n",
    "                ## Tuesday contains three days of data so smooth\n",
    "                ## daily figures over the weekend\n",
    "                for i in range(2,-1,-1):\n",
    "                    entry_date = data_date - timedelta(days = i)\n",
    "                    ds.append((entry_date.strftime(\"%Y-%m-%d\"), v / 3.0))\n",
    "            else:\n",
    "                ## Weekly figures don't need smoothing, nor do other days\n",
    "                ds.append((data_date.strftime(\"%Y-%m-%d\"), v))\n",
    "                \n",
    "        ## CSV data\n",
    "        new_rows = []\n",
    "        if file_date.weekday() == TUESDAY:\n",
    "            ## Tuesday's data contains three days of data\n",
    "            for i in range(2,-1,-1):\n",
    "                row = []\n",
    "                entry_date = data_date - timedelta(days = i)\n",
    "                row.append(entry_date.strftime(\"%Y-%m-%d\"))\n",
    "                for n in dataset_names:\n",
    "                    if n in smoothed_names:\n",
    "                        ## Smooth daily data over the weekend\n",
    "                        row.append(data[n] / 3.0)\n",
    "                    elif i > 0:\n",
    "                        ## Omit weekly data over the weekend\n",
    "                        row.append('')\n",
    "                    else:\n",
    "                        ## Still output Monday's weekly data\n",
    "                        row.append(data[n])\n",
    "                      \n",
    "                new_rows.append(row)\n",
    "        else:\n",
    "            ## Days other than Tuesday are treated normally\n",
    "            row = []\n",
    "            row.append(data_date.strftime(\"%Y-%m-%d\"))\n",
    "            for n in dataset_names:\n",
    "                row.append(data[n])\n",
    "            new_rows.append(row)\n",
    "        rows.extend(new_rows)\n",
    "        \n",
    "        last_data = data\n",
    "    else:\n",
    "        print(\"File is a duplicate\", file.name)\n",
    "        #file.rename(duplicates / file.name)\n",
    "        \n",
    "ofh = open(\"../data/covid.json\", \"w\", newline='')\n",
    "json.dump(datasets, ofh, sort_keys=True, indent=4)\n",
    "ofh.close()\n",
    "        \n",
    "with open(\"../data/covid.csv\", \"w\", newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile)\n",
    "    for row in rows:\n",
    "        datawriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, <th scope=\"col\">Â </th>),\n",
       " (1, <th colspan=\"2\" rowspan=\"1\" scope=\"col\">Staff</th>),\n",
       " (2, <th colspan=\"2\" rowspan=\"1\" scope=\"col\">Students</th>),\n",
       " (3, <td>Â </td>),\n",
       " (4, <td>On campus *</td>),\n",
       " (5, <td>Off campus **</td>),\n",
       " (6, <td>On campus *</td>),\n",
       " (7, <td>Off campus **</td>),\n",
       " (8, <td>New cases in last counted 24 hour period ***</td>),\n",
       " (9, <td>1</td>),\n",
       " (10, <td>1</td>),\n",
       " (11, <td>21</td>),\n",
       " (12, <td>7</td>),\n",
       " (13, <td>New cases in last counted 7 day period ***</td>),\n",
       " (14, <td>6</td>),\n",
       " (15, <td>3</td>),\n",
       " (16, <td>129</td>),\n",
       " (17, <td>17</td>),\n",
       " (18, <td>Total cases since 28 Sept 2020 (start of Term 1)</td>),\n",
       " (19, <td>9</td>),\n",
       " (20, <td>4</td>),\n",
       " (21, <td>159</td>),\n",
       " (22, <td>31</td>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(table.find_all([\"td\",\"th\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
